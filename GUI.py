# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'C:\Users\tonyt\test.ui'
#
# Created by: PyQt5 UI code generator 5.15.10
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets

import cv2
import face_recognition
import matplotlib.pyplot as plt
import scipy # another useful library 
import os
import math
import numpy as np
import random


def show_warning(prompt):
    msg_box = QtWidgets.QMessageBox()
    msg_box.setIcon(QtWidgets.QMessageBox.Warning)
    msg_box.setWindowTitle("Warning")
    msg_box.setText(prompt)
    msg_box.exec_()

def halo_effect(image, face, alpha):
    for (x, y, w, h) in face:
        center = (x+w//2, y+h//2)
        radii = (w//2, h//2)
        num_lines = int(alpha * 0.3 + 20)
        line_length = 20 

        for i in range(num_lines):
            if random.randint(0, 5) == 0:
                continue
            angle_rad = math.radians(i * (360 / num_lines))
            start_point = (
                int(random.uniform(1, 1.1) * (center[0] + radii[0] * math.cos(angle_rad))),
                int(random.uniform(1, 1.1) * (center[1] + radii[1] * math.sin(angle_rad)))
            )
            while start_point[0] > 0 and start_point[1] > 0 and start_point[0] < image.shape[1] and start_point[1] < image.shape[0]:
                line_mask = np.zeros_like(image)
                end_point = (
                    int(start_point[0] + line_length * math.cos(angle_rad)),
                    int(start_point[1] + line_length * math.sin(angle_rad))
                )
                color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
                cv2.line(line_mask, start_point, end_point, color)
                if random.randint(0, 1) == 0:
                    kernel_size = random.choice([3, 5, 7])
                    line_mask = cv2.GaussianBlur(line_mask, (kernel_size, kernel_size), 0)
                hsv = cv2.cvtColor(line_mask, cv2.COLOR_BGR2HSV)
                hsv[:, :, 1] = np.clip(hsv[:, :, 1] * random.uniform(0.2, 2), 0, 255)
                line_mask = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
                image += line_mask

                start_point = end_point
                
    return image 
def get_face(image):
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    face = face_classifier.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))
    return face

def add_film_grain_gray(image, mean, sigma=5):
    #"""Add film grain (noise) to the image."""
    row, col = image.shape
    gauss = np.random.normal(mean*0.8+20, sigma, (row, col)).astype(np.uint8)
    noisy_image = cv2.add(image, gauss)
    return noisy_image


def add_film_grain_rgb(image, mean=0, sigma=0.01):
    #"""Add film grain (noise) to the color image."""
    row, col, ch = image.shape  # Get the dimensions for a color image
    gauss = np.random.normal(mean, sigma, (row, col, ch)).astype(np.float32)
    
    # Add the noise and clip to the valid range
    noisy_image = image.astype(np.float32) + gauss
    noisy_image = np.clip(noisy_image, 0, 255)

    return noisy_image.astype(np.uint8)




def add_vignette(image, strength=0.5):
    rows, cols = image.shape[:2]
    # Create a vignette mask
    X_resultant_kernel = cv2.getGaussianKernel(cols, cols * strength)
    Y_resultant_kernel = cv2.getGaussianKernel(rows, rows * strength)

    # Generating the final mask
    mask = Y_resultant_kernel * X_resultant_kernel.T
    # Normalizing the mask
    mask = mask / mask.max()
    # Applying the mask to each channel in the input image
    for i in range(3):
        image[:, :, i] = image[:, :, i] * mask

    return image

def film_filter(img, mean): 
    #apply border

    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    grain_gray_image = add_film_grain_gray(gray_image, mean)
    grain_gray_bgr = cv2.cvtColor(grain_gray_image, cv2.COLOR_GRAY2BGR)
    old_timey_image = add_vignette(grain_gray_bgr)

    #add black and white
    #add grain 
    return old_timey_image 


def sepia_filter(img):
    
    img_sepia = np.array(img, dtype = np.float64) # prevents loss 
    img_sepia = cv2.transform(img_sepia, np.matrix([[0.272, 0.534, 0.131],
                                                    [0.349, 0.686, 0.168],
                                                    [0.393, 0.769, 0.189]])) #sepia matrix 
                                                    
    img_sepia[np.where(img_sepia > 255)] = 255 # removes higher values and puts it to 255
    img_sepia = np.array(img_sepia, dtype = np.uint8)
    return img_sepia

#grey pencil sketch effect
def pencil_sketch_grey(img, alpha):
    #inbuilt function to create sketch effect in colour and greyscale
    sk_gray, sk_color = cv2.pencilSketch(img, sigma_s=1, sigma_r=0.07, shade_factor=alpha/200) 
    return  sk_gray


#invert filter
def invert(img):
    inv = cv2.bitwise_not(img)
    return inv


# def apply_burned_edges(image, mask_path):
#     # Load the mask
#     mask = cv2.imread(mask_path, 0)

#     # Resize the mask to match the image size
#     mask = cv2.resize(mask, (image.shape[1], image.shape[0]))

#     # Apply the mask to the image
#     burned_image = cv2.bitwise_and(image, image, mask=mask)
#     return burned_image    


def apply_burned_edges(image):
    # Load the mask
    mask = cv2.imread("files_for_processing/effect_assets/film2.png", 0)
    if mask is None:
        raise FileNotFoundError(f"Mask image not found at {mask}")

    # Resize the mask to match the image size
    mask = cv2.resize(mask, (image.shape[1], image.shape[0]))

    # Apply the mask to the image
    burned_image = cv2.bitwise_and(image, image, mask=mask)
    return burned_image



def overlay_on_film_frame(photo, scale_factor=1.0):
    # Load the film frame with alpha channel (transparency)
    film_frame = cv2.imread("files_for_processing/effect_assets/film2.png", cv2.IMREAD_UNCHANGED)

    if photo is None:
        raise ValueError("The 'filmed' image has not been loaded correctly.")
    if film_frame is None: 
        raise ValueError("the border is not loaded")
    
    # Resize photo to fit in the film frame
    resized_photo = cv2.resize(photo, (int(film_frame.shape[1] * scale_factor), 
                                      int(film_frame.shape[0] * scale_factor)))

    # Split the film frame into its color and alpha (transparency) channels
    b, g, r, a = cv2.split(film_frame)
    film_frame_rgb = cv2.merge([b, g, r])
    film_frame_alpha = cv2.merge([a, a, a])

    # Overlay the photo on the film frame
    overlay = np.where(film_frame_alpha == 255, resized_photo, film_frame_rgb)
    return overlay

class Ui_Dialog(object):
    last_filter = None
    file_path = None
    def setupUi(self, Dialog):
        Dialog.setObjectName("Dialog")
        Dialog.resize(1100, 1000)
        self.HaloBtn = QtWidgets.QPushButton(Dialog)
        self.HaloBtn.setGeometry(QtCore.QRect(30, 900, 141, 71))
        self.HaloBtn.setObjectName("HaloBtn")
        self.ImageLabel = QtWidgets.QLabel(Dialog)
        self.ImageLabel.setGeometry(QtCore.QRect(350, 240, 381, 381))
        self.ImageLabel.setFrameShape(QtWidgets.QFrame.Box)
        self.ImageLabel.setText("")
        self.ImageLabel.setScaledContents(True)
        self.ImageLabel.setAlignment(QtCore.Qt.AlignCenter)
        self.ImageLabel.setObjectName("ImageLabel")
        self.UploadImageBtn = QtWidgets.QPushButton(Dialog)
        self.UploadImageBtn.setGeometry(QtCore.QRect(450, 110, 191, 51))
        self.UploadImageBtn.setObjectName("UploadImageBtn")
        self.BWfilter = QtWidgets.QPushButton(Dialog)
        self.BWfilter.setGeometry(QtCore.QRect(200, 900, 141, 71))
        self.BWfilter.setObjectName("BWfilter")
        self.Inverted = QtWidgets.QPushButton(Dialog)
        self.Inverted.setGeometry(QtCore.QRect(370, 900, 141, 71))
        self.Inverted.setObjectName("Inverted")
        self.Sketchy = QtWidgets.QPushButton(Dialog)
        self.Sketchy.setGeometry(QtCore.QRect(540, 900, 141, 71))
        self.Sketchy.setObjectName("Sketchy")
        self.Old = QtWidgets.QPushButton(Dialog)
        self.Old.setGeometry(QtCore.QRect(710, 900, 141, 71))
        self.Old.setObjectName("Old")
        self.Film = QtWidgets.QPushButton(Dialog)
        self.Film.setGeometry(QtCore.QRect(880, 900, 141, 71))
        self.Film.setObjectName("Film")
        self.horizontalSlider = QtWidgets.QSlider(Dialog)
        self.horizontalSlider.setGeometry(QtCore.QRect(230, 740, 591, 20))
        self.horizontalSlider.setOrientation(QtCore.Qt.Horizontal)
        self.horizontalSlider.setObjectName("horizontalSlider")
        self.horizontalSlider.setMinimum(1)
        self.horizontalSlider.setMaximum(100)

        self.retranslateUi(Dialog)
        self.HaloBtn.clicked.connect(self.haloBtnClicked)
        self.UploadImageBtn.clicked.connect(self.onBrowseClicked) 
        self.BWfilter.clicked.connect(self.TVfilter) 
        self.Inverted.clicked.connect(self.inverted_filter) 
        self.Sketchy.clicked.connect(self.sketchy_filter)
        self.Old.clicked.connect(self.sepia_filter) 
        #self.Film.clicked.connect() 
        self.horizontalSlider.valueChanged['int'].connect(self.sliderValueChanged)
        QtCore.QMetaObject.connectSlotsByName(Dialog)

    def retranslateUi(self, Dialog):
        _translate = QtCore.QCoreApplication.translate
        Dialog.setWindowTitle(_translate("Dialog", "Dialog"))
        self.HaloBtn.setText(_translate("Dialog", "Show Halo"))
        self.UploadImageBtn.setText(_translate("Dialog", "Upload Image"))
        self.BWfilter.setText(_translate("Dialog", "80s TV filter"))
        self.Inverted.setText(_translate("Dialog", "Inverted Filter"))
        self.Sketchy.setText(_translate("Dialog", "Sketchy Filter"))
        self.Old.setText(_translate("Dialog", "Sepia Filter"))
        self.Film.setText(_translate("Dialog", "Film Filter"))

    def onBrowseClicked(self):
        _translate = QtCore.QCoreApplication.translate
        file_dialog = QtWidgets.QFileDialog()
        file_dialog.setNameFilter("Images (*.png *.jpg *.bmp)")
        file_dialog.setFileMode(QtWidgets.QFileDialog.ExistingFile)

        if file_dialog.exec_():
            self.file_path = file_dialog.selectedFiles()[0]
            self.ImageLabel.setPixmap(QtGui.QPixmap(self.file_path))
            self.last_filter = None

    def haloBtnClicked(self):
        
        if self.file_path:
            face = get_face(cv2.imread(self.file_path))
            if len(face) > 0:
                self.tab_count = plt.get_fignums()
                print(self.tab_count)
                self.face = face
                image = cv2.cvtColor(cv2.imread(self.file_path), cv2.COLOR_BGR2RGB)
                halo_image = halo_effect(image, face, self.horizontalSlider.value())
                
                plt.clf()
                plt.imshow(halo_image)
                plt.title("Halo Filter")
                plt.axis('off')
                self.show_plot()
                self.last_filter = "halo"
            else:
                show_warning("No face detected")
            
        else:
            show_warning("Please upload an image first.")
            

    def TVfilter(self):
        if self.file_path:
            filmed = film_filter(cv2.imread(self.file_path), self.horizontalSlider.value())
            self.tab_count = plt.get_fignums()
            plt.clf()
            plt.imshow(filmed)
            plt.axis("off")
            plt.title("TV filter")
            self.show_plot()
            self.last_filter = "TV"
        else:
            show_warning("Please upload an image first.")

    def inverted_filter(self):
        if self.file_path:
            a9 = invert(cv2.imread(self.file_path))
            image_rgb = cv2.cvtColor(a9, cv2.COLOR_BGR2RGB) # cv2 is bgr whilte matpllot lib is rgb 
            self.tab_count = plt.get_fignums()
            plt.clf()
            plt.imshow(image_rgb)
            plt.title("Inverted Filter")
            plt.axis("off")
            self.show_plot()
            self.last_filter = "inverted"
        else:
            show_warning("Please upload an image first.")
    
    def sketchy_filter(self):
        if self.file_path:
            sketchy_image = pencil_sketch_grey(cv2.imread(self.file_path), self.horizontalSlider.value()) 
            self.tab_count = plt.get_fignums()
            plt.clf()
            plt.imshow(sketchy_image, cmap='gray')
            plt.title("Sketchy Filter")
            plt.axis("off")
            self.show_plot()
            self.last_filter = "sketchy"
        else:
            show_warning("Please upload an image first.")
    
    def sepia_filter(self):
        if self.file_path:
            sepia_bovik = sepia_filter(cv2.imread(self.file_path))
            sepia_image_rgb = cv2.cvtColor(sepia_bovik, cv2.COLOR_BGR2RGB)
            sepia_noise = add_film_grain_rgb(sepia_image_rgb)
            self.tab_count = plt.get_fignums()
            plt.clf()
            #plt.imshow(sepia_image_rgb)
            plt.imshow(sepia_noise)

            plt.title("Sepia Filter")
            plt.axis("off")
            self.show_plot()
            self.last_filter = "sepia"

        else:
            show_warning("Please upload an image first.")
            self.show_plot()

    def film_filter(self):
        if self.file_path:
            filmed_burned = overlay_on_film_frame(cv2.imread(self.file_path))
            self.tab_count = plt.get_fignums()
            plt.clf()
            plt.imshow(filmed_burned)
            plt.title("Film Filter")
            plt.axis("off")
            self.show_plot()
            self.last_filter = "film"

            img_burn = apply_burned_edges(filmed_burned)
            plt.imshow(img_burn)
            plt.title("alte")
            plt.axis("off")
            self.show_plot()
        else:
            show_warning("Please upload an image first.")
    
    def show_plot(self):
        if self.tab_count:
            plt.draw()
        else:
            plt.show()

    def sliderValueChanged(self):
        if plt.get_fignums():
            plt.clf()
            if self.last_filter == "TV":
                plt.imshow(film_filter(cv2.imread(self.file_path), self.horizontalSlider.value()))
                plt.axis("off")
                plt.title("TV filter")
            elif self.last_filter == "sketchy":
                plt.imshow(pencil_sketch_grey(cv2.imread(self.file_path), self.horizontalSlider.value()), cmap='gray')
                plt.title("Sketchy Filter")
                plt.axis("off")
            elif self.last_filter == "halo":
                plt.imshow(halo_effect(cv2.cvtColor(cv2.imread(self.file_path), cv2.COLOR_BGR2RGB), self.face, self.horizontalSlider.value()))
                plt.title("Halo Filter")
                plt.axis('off')
            plt.draw()



if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    Dialog = QtWidgets.QDialog()
    ui = Ui_Dialog()
    ui.setupUi(Dialog)
    Dialog.show()
    sys.exit(app.exec_())




